{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 卷积\n",
    "* 稀疏连接 让学习参数变得很少\n",
    "* 平移不变性 不关心物体出现在图像什么位置\n",
    "* 卷积计算过程\n",
    "  * ![](images/convolution-2022-09-28-10-49-08.png)\n",
    "  * 输入特征图 m个通道，宽w,高h\n",
    "  * 输出有n个特征图,宽h',高w'\n",
    "  * 卷积核大小kxk，m通道，总共n个卷积核，卷积核核数=输出的特征图的通道数\n",
    "  * 多通道时卷积\n",
    "    * 输入特征图的第i个特征图与卷积核中的第i个通道进行卷积，生成m个特征图，后将这m个特征图对应位置求和，\n",
    "    * m个特征图合并为输出特征图中一个通道的特征图\n",
    "  * padding\n",
    "    * 多层卷积时，特征图会一点点变小，可以减缓变小速度，在计算卷积时，对输入特征图补0\n",
    "      * 保持输入输出size一致  \n",
    "      * 让输入特征保留更多信息\n",
    "    * padding=1 补一圈的0 =2 补2圈的0\n",
    "    * ![](images/convolution-2022-09-28-11-07-47.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pytorch中的卷积\n",
    "`\n",
    "# Conv2d类   \n",
    "```\n",
    "class torch.nn.Conv2d(in_channels, #输入特征图的通道数\n",
    "                      out_channels, #输出特征图的通道数\n",
    "                      kernel_size, # 卷积核大小\n",
    "                      stride=1, #步长 default=1\n",
    "                      padding=0, #when padding='valid'(没有padding) or 'same'(让输出特征图和输入特征图大小一致) stride must=1\n",
    "                      整数时，表示特征图外边补多少圈0\n",
    "                      tuple时，表示在特征图的行/列补多少零\n",
    "                      dilation=1, \n",
    "                      groups=1, \n",
    "                      bias=True, \n",
    "                      padding_mode='zeros', \n",
    "                      device=None, \n",
    "                      dtype=None)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4., 1., 7., 5.],\n",
      "        [4., 4., 2., 5.],\n",
      "        [7., 7., 2., 4.],\n",
      "        [1., 0., 2., 4.]])\n",
      "torch.Size([4, 4])\n",
      "Parameter containing:\n",
      "tensor([[[[ 0.0770,  0.4122],\n",
      "          [-0.4616,  0.0716]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2050], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[1., 0.],\n",
      "          [2., 1.]]]])\n",
      "Parameter containing:\n",
      "tensor([-0.2050], requires_grad=True)\n",
      "tensor([[[[4., 1., 7., 5.],\n",
      "          [4., 4., 2., 5.],\n",
      "          [7., 7., 2., 4.],\n",
      "          [1., 0., 2., 4.]]]])\n",
      "torch.Size([1, 1, 4, 4])\n",
      "tensor([[[[15.7950, 10.7950, 15.7950, 14.7950],\n",
      "          [24.7950, 19.7950,  9.7950, 12.7950],\n",
      "          [ 8.7950,  8.7950,  9.7950, 11.7950],\n",
      "          [ 0.7950, -0.2050,  1.7950,  3.7950]]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "input_feat = torch.tensor([[4, 1, 7, 5], [4, 4, 2, 5], [7, 7, 2, 4], [1, 0, 2, 4]], dtype=torch.float32)\n",
    "print(input_feat)\n",
    "print(input_feat.shape)\n",
    "\n",
    "conv2d = nn.Conv2d(1, 1, (2,2),stride=1, padding='same',bias=True)\n",
    "print(conv2d.weight)\n",
    "print(conv2d.bias)\n",
    "\n",
    "# 卷积核要有四个维度(输入通道数，输出通道数，高，宽)\n",
    "kernels = torch.tensor([[[[1, 0], [2, 1]]]], dtype=torch.float32)\n",
    "conv2d.weight = nn.Parameter(kernels, requires_grad=False)\n",
    "\n",
    "print(conv2d.weight)\n",
    "print(conv2d.bias)\n",
    "\n",
    "#pytorch 输入tensor的维度信息是 (batch_size, 通道数，宽，高)\n",
    "# output = conv2d(input_feat)\n",
    "# print(output)\n",
    "input_feat1 =  input_feat.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "print(input_feat1)\n",
    "print(input_feat1.shape)\n",
    "\n",
    "\n",
    "output = conv2d(input_feat1)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 卷积的变种\n",
    "|卷积|说明|\n",
    "|---|---|\n",
    "|深度可分离卷积|用于轻量化模型|\n",
    "|空洞卷积|图像分割|\n",
    "|转置卷积|图像分割|\n",
    "|残差卷积|为了提高网络精度的一种组合|\n",
    "|inception模块|为了提高网络精度的一种组合|\n",
    "|SE块|为了提高网络精度的一种组合|\n",
    "\n",
    "## 深度可分离卷积\n",
    "* DW 卷积 ，\n",
    "  * 标准卷积计算\n",
    "  ![](images/convolution-2022-09-28-15-58-09.png)   \n",
    "  * DW depthwise卷积\n",
    "    * 有m个卷积核的卷积，每个卷积核的通道数为1，输出为m个通道的特征图\n",
    "    * ![](images/convolution-2022-09-28-16-03-06.png)\n",
    "* PW pointwise卷积\n",
    "  * 就是标准卷积，不过卷积核为1x1\n",
    "  * 逐点卷积，将DW输出的m个特征图，输出一个n通道的特征图\n",
    "  * 实现方式为n个卷积核为1x1的卷积，每个卷积核的通道数为m\n",
    "  * ![](images/convolution-2022-09-28-16-06-16.png)\n",
    "  * 可以获得一个与标准卷积相同尺寸的结果\n",
    "* 计算量\n",
    "  * 标准卷积\n",
    "    * `k*k*m*n*h'*w'`\n",
    "  * 可分离卷积\n",
    "    * `k*k*m*h'*w'+1*1*m*n*h'*w'`\n",
    "  * 二者之比为\n",
    "    * `1/n+1/(k*k)`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pytorch 实现深度可分离\n",
    "```\n",
    " torch.nn.Conv2d(in_channels, \n",
    " out_channels, \n",
    " kernel_size, \n",
    " stride=1, \n",
    " padding=0, \n",
    " dilation=1, \n",
    " groups=1, \n",
    " bias=True, \n",
    " padding_mode='zeros', \n",
    " device=None, \n",
    " dtype=None)\n",
    "```\n",
    "* groups =1 为标准卷积\n",
    "* groups 不等于1时，输入特征图会分成groups组，每组有自己的卷积核，最后输出的特征图有groups个分组，必须能整除in_channels,out_channels\n",
    "* groups = in_channels时，即DW卷积\n",
    "* Attention\n",
    "  * DW中，输入特征通道数和输出通道数一致\n",
    "  * 一般DW卷积核3x3\n",
    "  * DW卷积的groups参数和输出通道数一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 5, 5])\n",
      "torch.Size([1, 4, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "#[batchsize, channel,width,height]\n",
    "x =torch.rand((3,5,5)).unsqueeze(0)\n",
    "print(x.shape)\n",
    "\n",
    "#DW中，输入特征通道数和输出通道数一致\n",
    "in_channels_dw = x.shape[1]\n",
    "out_channels_dw = x.shape[1]\n",
    "\n",
    "#一般DW卷积核大小3\n",
    "kernel_size =3 \n",
    "stride =1\n",
    "dw = nn.Conv2d(in_channels_dw, out_channels_dw,kernel_size,\n",
    "stride,\n",
    "groups = in_channels_dw\n",
    ")\n",
    "\n",
    "\n",
    "in_channels_pw = out_channels_dw\n",
    "out_channels_pw = 4\n",
    "kernel_size_pw = 1\n",
    "pw = nn.Conv2d(in_channels_pw, out_channels_pw, kernel_size_pw, stride)\n",
    "out = pw(dw(x))\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 空洞卷积\n",
    "* 常用于图像分割中(对每个像素点都进行预测)\n",
    "* 图像分割模型，会采用多层卷积来提取特征，随着层数的不断加深，感受野也越来越大，但是对于图像分割模型，经过多层的卷积和pooling后，特征图会变小。为了做到每个像素点都有预测输出，需要对较小的特征图进行上采样或反卷积，将特征图扩大到一定尺度，然后再进行预测。\n",
    "* 从一个较小的特征图恢复到较大的特征图，会带来一定的信息损失，所以为了保证有较大的感受野，同时又不用缩小特征图-空洞卷积\n",
    "* 卷积中的pool层(使特征图变小)以及卷积层，使得特征图越来越小，不同层的特征图的计算区域不同-感受野(卷积输出时一个单元在输入特征图中代表的单元数)。感受野越大标识包含的信息更加全面，语义信息更加抽象，越小，代表这个包含更加细节的语义信息。\n",
    "* 计算过程\n",
    "  * 将卷积核以一定比例拆分开\n",
    "  * 标准卷积\n",
    "    * ![](images/convolution-2022-09-28-21-00-18.png)\n",
    "  * 空洞卷积\n",
    "    * ![](images/convolution-2022-09-28-21-00-45.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 10, 126, 126])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "#[batchsize, channel,width,height]\n",
    "x =torch.rand((3,128,128)).unsqueeze(0)\n",
    "print(x.shape)\n",
    "\n",
    "\n",
    "in_channels_dw = x.shape[1]\n",
    "out_channels_dw = x.shape[1]\n",
    "\n",
    "#一般DW卷积核大小3\n",
    "kernel_size =3 \n",
    "stride =1\n",
    "dw = nn.Conv2d(in_channels_dw, out_channels_dw, kernel_size,\n",
    "stride,\n",
    "groups = in_channels_dw\n",
    ")\n",
    "\n",
    "in_channels_pw = out_channels_dw\n",
    "out_channels_pw = 10\n",
    "pw = nn.Conv2d(in_channels_pw, out_channels_pw, 1)\n",
    "output = pw(dw(x))\n",
    "print(output.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "95dc1df185fd18e9076d56f64a89076aab4b6948bfab183b6c1ff3b5009283ae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
